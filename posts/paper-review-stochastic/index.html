<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Stochastic Approximation to Contrastive Learning | MookStudy</title><meta name=keywords content="Paper Review,Self-Supervised Learning,Contrastive Learning,Stochastic Approximation,ICLR 2025"><meta name=description content="This post reviews &lsquo;Stochastic Approximation to Contrastive Learning,&rsquo; a paper submitted to ICLR 2025. While ultimately rejected, the paper proposed an interesting approach to make contrastive learning more efficient. I&rsquo;ll break down its core ideas, the community&rsquo;s feedback, and why it fell short."><meta name=author content="Jungmook Kang"><link rel=canonical href=https://mookjsi.github.io/posts/paper-review-stochastic/><link crossorigin=anonymous href=/assets/css/stylesheet.03596ecd86a161ae014a0dfa94c2124c406fa319ff0dbb5cccfcd08aa1787188.css integrity="sha256-A1luzYahYa4BSg36lMISTEBvoxn/DbtczPzQiqF4cYg=" rel="preload stylesheet" as=style><link rel=icon href=https://mookjsi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mookjsi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mookjsi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://mookjsi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://mookjsi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mookjsi.github.io/posts/paper-review-stochastic/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta property="og:url" content="https://mookjsi.github.io/posts/paper-review-stochastic/"><meta property="og:site_name" content="MookStudy"><meta property="og:title" content="Stochastic Approximation to Contrastive Learning"><meta property="og:description" content="This post reviews ‘Stochastic Approximation to Contrastive Learning,’ a paper submitted to ICLR 2025. While ultimately rejected, the paper proposed an interesting approach to make contrastive learning more efficient. I’ll break down its core ideas, the community’s feedback, and why it fell short."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-05T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-05T00:00:00+00:00"><meta property="article:tag" content="Paper Review"><meta property="article:tag" content="Self-Supervised Learning"><meta property="article:tag" content="Contrastive Learning"><meta property="article:tag" content="Stochastic Approximation"><meta property="article:tag" content="ICLR 2025"><meta name=twitter:card content="summary"><meta name=twitter:title content="Stochastic Approximation to Contrastive Learning"><meta name=twitter:description content="This post reviews &lsquo;Stochastic Approximation to Contrastive Learning,&rsquo; a paper submitted to ICLR 2025. While ultimately rejected, the paper proposed an interesting approach to make contrastive learning more efficient. I&rsquo;ll break down its core ideas, the community&rsquo;s feedback, and why it fell short."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://mookjsi.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Stochastic Approximation to Contrastive Learning","item":"https://mookjsi.github.io/posts/paper-review-stochastic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Stochastic Approximation to Contrastive Learning","name":"Stochastic Approximation to Contrastive Learning","description":"This post reviews \u0026lsquo;Stochastic Approximation to Contrastive Learning,\u0026rsquo; a paper submitted to ICLR 2025. While ultimately rejected, the paper proposed an interesting approach to make contrastive learning more efficient. I\u0026rsquo;ll break down its core ideas, the community\u0026rsquo;s feedback, and why it fell short.","keywords":["Paper Review","Self-Supervised Learning","Contrastive Learning","Stochastic Approximation","ICLR 2025"],"articleBody":"This is my detailed slide-by-slide analysis of the paper Stochastic Approximation to Contrastive Learning, which was submitted to the ICLR 2025 conference.\nThe paper tackles a critical challenge in contrastive learning: its heavy reliance on large batch sizes and the associated computational cost. The authors introduce SACLR, a novel framework inspired by Stochastic Cluster Embedding (SCE) that reformulates the objective using I-divergence. The goal was to enable efficient training with as little as one negative sample, a significant departure from methods like SimCLR.\nWhile the premise is compelling, the paper faced substantial criticism during the open review process regarding its experimental comparisons, novelty, and the substantiation of its claims. Despite rebuttals and additional experiments, it was ultimately rejected. In this review, I’ll walk through the method as presented and layer in the context from the public reviews to provide a complete picture of its strengths and weaknesses.\nThis is the title slide for my review of the paper “Stochastic Approximation to Contrastive Learning.” This presentation was prepared for the Information Theory and Machine Learning Lab at Yonsei University.\nTo begin, I’ll recap the core concept of Representation Learning. This field is all about how we represent data, which leads to the fundamental question: what exactly is a “representation” in the context of machine learning?\nI’ll illustrate this with a simple task. Imagine you need to solve the division problem CCV / VI. For most people, this is not immediately obvious.\nNow, consider this problem: 210 / 6. This is likely much easier, and you can quickly determine the answer is 35. The interesting part is that both problems represent the exact same calculation.\nThe key difference lies in the representation of the same numerical information. The first task used Roman numerals, while the second used Arabic numerals. The choice of representation dramatically changes the difficulty of the task.\nThis analogy illustrates a critical point that is central to representation learning: the right representation can make a complex task much easier to solve.\nTo summarize this introductory point: the difficulty of many information processing tasks is highly dependent on how that information is represented.\nSo, the crucial question for us is: how can we obtain a “good representation” for various machine learning tasks? Today, I’ll focus on one prominent approach for achieving this: Self-Supervised Learning.\nSelf-Supervised Learning is a subset of the broader field of Representation Learning.\nA primary motivation for the development of self-supervised methods is the immense cost and effort required to obtain large-scale labeled datasets for traditional supervised learning.\nThe solution that Self-Supervised Learning proposes is to find a way to learn a “good representation” that captures the essential features of the data using only an unlabeled dataset.\nThis slide illustrates the typical self-supervised learning pipeline. First, a model is trained on a “pretext task” using a large amount of unlabeled data. The learned model is then transferred and fine-tuned on a “downstream task” using task-specific (and often limited) labeled data.\nThe goal of the pre-training stage is to transform raw data, which can be a poor representation for a computer (like a raw image of a dog), into a feature vector that is a much better representation for downstream tasks.\nThe central question this paper investigates is the pre-training step: how exactly does the model learn a good representation from unlabeled data?\nWithin the realm of Self-Supervised Learning, I will now narrow the focus to Contrastive Learning. This approach is based on making “inter-sample” predictions.\nHere is the core mechanic of contrastive learning. We start with an “anchor” image. We create two different augmented versions, or “views,” of this anchor, which form a “positive pair.” We then contrast this with a “negative pair,” which is formed by the anchor and a view from a completely different image.\nIn summary, the objective of contrastive learning is to learn effective representations by mapping similar data points close to each other in the representation space, while simultaneously pushing dissimilar data points far apart.\nThis slide outlines the flow of the main arguments in this review. I’ll begin by discussing the high computational costs that arise from the conventional definition of positive and negative pairs. Then, I will introduce the paper’s proposed method, which uses matrix approximation with I-divergence to create a decomposable and stochastic loss, ultimately achieving competitive results with a low batch size and fewer negative pairs.\nNow, we move from the recap to the main introduction of the paper’s contribution.\nThe core problem is that while supervised learning is effective, it depends on having extensive labeled data. Self-Supervised Learning is the alternative we are exploring.\nHowever, popular contrastive learning methods like SimCLR require very large batch sizes to ensure a sufficient balance of positive and negative examples. This expends a large amount of computational resources, particularly on the negative pairs. A method called Sog-CLR attempted to address this by mixing an EMA of image similarities into the denominator of the InfoNCE loss.\nTo be more specific, SimCLR’s InfoNCE loss operates in a full-batch mode, which is not decomposable in a mini-batch setting. Sog-CLR showed improvement by incorporating a running average for the negative pair estimations.\nThis paper poses the question: even with Sog-CLR’s improvements, is there still room for further optimization? It introduces SACLR, a method that uses I-divergence to reformulate the objective into a matrix approximation problem that is decomposable across instance pairs.\nThe key idea behind SACLR is this reformulation using I-divergence, which allows the objective to be decomposed and approximated stochastically. This is presented as an advancement over Sog-CLR’s EMA mixing approach.\nThe paper’s central claim is that its method, SACLR, can learn high-quality representations with a small batch size and very few negative pairs. While reviewers found the core idea of tackling the large batch size problem to be an interesting and valuable contribution, and saw the novel formulation inspired by Stochastic Cluster Embedding as a strength, they heavily scrutinized the experimental evidence supporting these claims.\nTo understand SACLR, we first need to look at its theoretical foundation: Stochastic Cluster Embedding (SCE). I will now detail the matrix approximation with I-divergence that underpins the method.\nIn SCE, we have embedded data points, like $y_i$ and $y_j$. We define a similarity kernel $q_{ij}$ between these points in the embedded space, typically using a Gaussian or a Student’s t-distribution kernel. This value should be close to 1 for similar points.\nWe also define a target similarity matrix, P, which represents the desired similarities in the embedded space. For example, perfectly clustered data would have a block-diagonal P matrix.\nThe goal is to make the learned similarity matrix Q as close as possible to our desirable target matrix P. The question is, how do we measure this closeness?\nThis is where the choice of divergence metric is crucial. t-SNE uses the KL-divergence. In contrast, SCE uses the I-divergence, which includes an additional scaling factor ’s’ and linear terms.\nThis slide highlights the formulas for both KL-divergence, used in t-SNE, and the I-divergence with a scaling factor, used in SCE.\nAn important property is that the I-divergence can reduce to the KL-divergence. This happens if the scaling factor ’s’ is set to be the inverse of the sum of all kernel similarities, effectively normalizing the Q matrix.\nSCE defines the scaling factor ’s’ using a weighted sum controlled by the parameter α, which introduces additional repulsion to improve cluster quality. A key methodological point, raised by Reviewer C43T, was why ’s’ is treated as a constant during optimization when it is a function of the embeddings. The authors clarified that they use an interleaving optimization strategy: the model parameters are optimized while ’s’ is fixed, and then ’s’ is periodically updated based on the new embeddings.\nBy plugging this definition of the weights $w_{ij}$ into the formula for ’s’, the denominator term can be rewritten as a sum of two expectations.\nThese two expectations have clear interpretations: $E_1$ is the expected similarity for pairs drawn from the target distribution P, while $E_2$ is the expected similarity for pairs drawn uniformly at random from all possible pairs.\nThis formulation allows the I-divergence objective to be rewritten in a stochastic form, separating it into an attraction term based on the target distribution and a repulsion term based on the uniform distribution. The terms themselves are simple functions of the similarity $q_{ij}$.\nNow, let’s apply this SCE framework to Contrastive Learning. In our setting, for each input $x_i$, we generate two augmented views, $\\tilde{x}{i}^{(1)}$ and $\\tilde{x}{i}^{(2)}$. We denote their embeddings as $\\tilde{y}{i}^{(u)}$ and the similarity between any two embeddings as $q{ij}^{(u,v)}$.\nThe goal in contrastive learning is to make embeddings from the same instance ($i=j$) similar, and embeddings from different instances ($i \\ne j$) dissimilar. We can formally define this as a target tensor $p$, where the target similarity is 1 only for positive pairs ($p_{ii}^{(1,2)}$ and $p_{ii}^{(2,1)}$) and 0 for all other pairs.\nThis slide provides a concrete example of the target tensor $P$ for a case with N=3 instances. The matrices for same-view similarities ($P^{(1,1)}, P^{(2,2)}$) are all zeros, while the matrices for cross-view similarities ($P^{(1,2)}, P^{(2,1)}$) are identity matrices, capturing the positive pair targets.\nTo simplify the math, we can flatten this four-dimensional tensor structure into standard 2D matrices. The $2N \\times 2N$ target matrix $\\psi$ is formed by reorganizing the elements of the tensor $p$. This results in a sparse matrix where the identity matrices from the tensor become off-diagonal blocks.\nFor notational simplicity, we neglect the diagonal elements of the matrices $\\psi$ and $\\phi$ in the approximation, as they are constant for the kernels used and do not affect the optimization.\nNow we apply the SCE I-divergence formula, but to our new flattened matrices $\\psi$ and $\\phi$ which represent the contrastive learning problem.\nApplying the I-divergence $D_{I}(\\psi||s\\phi)$ and using the specific structure of our target matrix $\\psi$ (which is mostly zeros), the loss function simplifies significantly. The scaling factor $s$ is updated periodically, with its weights $w_{ij}^{u,v}$ also adapted for the contrastive case.\nThe full loss function $\\mathcal{L}{CLR}(\\theta)$ can be expressed as an expectation over the data indices. This form consists of a term for positive pairs ($log~q{ii}^{1,2}$) and a repulsion term involving a sum of similarities over all pairs.\nTo make this computationally feasible, we use a Monte Carlo approximation. This gives us the final SACLR objective, $\\mathcal{L}{SACLR}(\\theta)$, which is calculated over a mini-batch $\\mathcal{B}$ and a set of M negative samples $\\mathcal{M}{i}$. The paper studies two variants: SACLR-1 (M=1) and SACLR-all (M=B).\nThe scaling factor $s$ is also estimated stochastically. Its inverse, $s^{-1}$, is approximated using samples from the mini-batch, and this estimate is updated smoothly using an exponential moving average (EMA) after each batch.\nThe paper also explores a row-wise decomposition of the matrix approximation. Instead of one global scaling factor ’s’, each row ‘a’ of the similarity matrix gets its own scaling factor $s_a$. This results in the loss function $\\mathcal{L}_{CLR-row}(\\theta)$.\nThis slide provides proof for the simplified row-wise SACLR loss function. By substituting the sparse target matrix $\\psi$ into the general I-divergence formula and summing over all rows, we arrive at the expression shown.\nA key theoretical finding presented in the paper is that under specific conditions, the SACLR-row objective becomes equivalent to the SimCLR loss. This link, however, became a point of discussion during the review. Reviewer gz9D argued that this equivalence doesn’t explain why SACLR should be expected to outperform SimCLR. The authors countered that the method’s advantage comes not from this specific condition, but from using a different, more flexible weighting scheme for the scaling factor.\nHere is the proof of Theorem 3.1. By substituting the condition for the scaling factors into the loss function, the repulsion term simplifies to a constant, and the remaining terms can be rearranged to form precisely the SimCLR objective.\nJust as with the full matrix version, the row-wise loss can be approximated stochastically for mini-batch training. This gives us the $\\mathcal{L}_{SACLR-row}(\\theta)$ objective.\nSimilarly, the row-wise scaling factors $s_{2(i-1)+u}$ are estimated stochastically within each mini-batch and updated using an EMA rule.\nThis diagram provides a summary of the theoretical framework I have just presented. We started with the concept of I-divergence and a scaling factor, which we used to build a matrix approximation. This was then decomposed row-wise, and both versions were made practical via stochastic approximation. Now, it’s time to see the experimental results.\nThis slide presents the full pseudocode for the SACLR algorithm. A major point of contention in the initial review was that the paper claimed to be “more computationally efficient” without providing empirical data on runtime or memory. The detailed ablation studies on computational cost, shown later in the presentation, were added during the rebuttal period as a direct response to this criticism from the reviewers.\nNow we move to the experiments section. The standard evaluation protocol for self-supervised methods is used: first, a model is pre-trained without labels on a dataset like ImageNet or CIFAR. The learned weights from this backbone are then used to initialize a new network, a linear layer is added, and this new network is trained with labels to perform a classification task.\nTable 1 shows the Top-1 linear classification accuracies on ImageNet. While SACLR-ALL is shown to be competitive with some methods like MoCo v2, this comparison drew significant criticism during the review process. The Area Chair and multiple reviewers stated that the baseline methods used for comparison were “weak” and the performance gains “marginal,” noting that many stronger, more recent methods were omitted.\nThis table shows results for longer training, with SACLR-MIX surpassing SimCLR and SogCLR in this setup. However, reviewers found this comparison inadequate as well. Reviewer gz9D pointed out that results for top-performing methods like VICReg and Barlow Twins from other benchmark papers were significantly higher. The authors argued their goal was primarily efficiency without heavy tuning, but this did not overcome the concerns about the weak comparison set.\nThis experiment in Table 3 specifically investigates performance when using only a single negative sample (M=1) per image. SACLR-1 achieves a Top-1 accuracy of 65.3%, significantly outperforming classical contrastive losses like Triplet and Logistic loss under the same constraint.\nThis table evaluates semi-supervised learning performance, showing SACLR’s strength in data-limited regimes. It is worth noting that the initial submission focused almost exclusively on linear evaluation. Reviewers Tx4K and gz9D strongly recommended including more comprehensive evaluations like semi-supervised fine-tuning to provide a more complete picture, and the additional kNN and fine-tuning results were added to the paper in response.\nThe learned representations are also evaluated on transfer learning classification tasks. As shown in Table 5, the representations learned by SACLR-ALL and SACLR-MIX transfer very well to other datasets like VOC07 and especially iNaturalist18, where they significantly outperform SimCLR and MoCo v2.\nTable 6 shows transfer learning results on more complex downstream tasks: object detection and segmentation on VOC and COCO. Across all metrics, the SACLR variants are highly competitive and often outperform strong baselines like SimCLR, BYOL, and MoCo v2, with SACLR-MIX showing the strongest results overall.\nThis table provides a direct comparison with other stochastic estimation-based contrastive methods, using an architecture similar to the iSog-CLR paper for a fair comparison. The results on CIFAR10, CIFAR100, and ImageNet100 show that both the matrix and row versions of SACLR are highly competitive, often achieving the best or second-best performance in this specific class of methods.\nThis slide presents several ablation studies on computational complexity and robustness. These experiments were largely added in response to direct reviewer feedback. Reviewers requested empirical data on runtime and memory to substantiate the paper’s efficiency claims, as well as a study on the impact of batch size to support the claim that SACLR performs well in small-batch settings. These tables represent the authors’ attempt to provide that missing evidence.\n","wordCount":"2631","inLanguage":"en","datePublished":"2025-03-05T00:00:00Z","dateModified":"2025-03-05T00:00:00Z","author":{"@type":"Person","name":"Jungmook Kang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mookjsi.github.io/posts/paper-review-stochastic/"},"publisher":{"@type":"Organization","name":"MookStudy","logo":{"@type":"ImageObject","url":"https://mookjsi.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mookjsi.github.io/ accesskey=h title="MookStudy (Alt + H)">MookStudy</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mookjsi.github.io/about/ title=About><span>About</span></a></li><li><a href=https://mookjsi.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://mookjsi.github.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://mookjsi.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mookjsi.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://mookjsi.github.io/posts/>Blog</a></div><h1 class="post-title entry-hint-parent">Stochastic Approximation to Contrastive Learning</h1><div class=post-meta><span title='2025-03-05 00:00:00 +0000 UTC'>March 5, 2025</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;2631 words&nbsp;·&nbsp;Jungmook Kang</div></header><div class=post-content><p>This is my detailed slide-by-slide analysis of the paper <strong>Stochastic Approximation to Contrastive Learning</strong>, which was submitted to the ICLR 2025 conference.</p><p>The paper tackles a critical challenge in contrastive learning: its heavy reliance on large batch sizes and the associated computational cost. The authors introduce SACLR, a novel framework inspired by Stochastic Cluster Embedding (SCE) that reformulates the objective using I-divergence. The goal was to enable efficient training with as little as one negative sample, a significant departure from methods like SimCLR.</p><p>While the premise is compelling, the paper faced substantial criticism during the open review process regarding its experimental comparisons, novelty, and the substantiation of its claims. Despite rebuttals and additional experiments, it was ultimately rejected. In this review, I&rsquo;ll walk through the method as presented and layer in the context from the public reviews to provide a complete picture of its strengths and weaknesses.</p><hr><p><img alt="Slide 1" loading=lazy src=/images/posts/stochastic/slide-01.jpg></p><blockquote><p>This is the title slide for my review of the paper &ldquo;Stochastic Approximation to Contrastive Learning.&rdquo; This presentation was prepared for the Information Theory and Machine Learning Lab at Yonsei University.</p></blockquote><p><img alt="Slide 2" loading=lazy src=/images/posts/stochastic/slide-02.jpg></p><blockquote><p>To begin, I&rsquo;ll recap the core concept of Representation Learning. This field is all about how we represent data, which leads to the fundamental question: what exactly is a &ldquo;representation&rdquo; in the context of machine learning?</p></blockquote><p><img alt="Slide 3" loading=lazy src=/images/posts/stochastic/slide-03.jpg></p><blockquote><p>I&rsquo;ll illustrate this with a simple task. Imagine you need to solve the division problem CCV / VI. For most people, this is not immediately obvious.</p></blockquote><p><img alt="Slide 4" loading=lazy src=/images/posts/stochastic/slide-04.jpg></p><blockquote><p>Now, consider this problem: 210 / 6. This is likely much easier, and you can quickly determine the answer is 35. The interesting part is that both problems represent the exact same calculation.</p></blockquote><p><img alt="Slide 5" loading=lazy src=/images/posts/stochastic/slide-05.jpg></p><blockquote><p>The key difference lies in the <em>representation</em> of the same numerical information. The first task used Roman numerals, while the second used Arabic numerals. The choice of representation dramatically changes the difficulty of the task.</p></blockquote><p><img alt="Slide 6" loading=lazy src=/images/posts/stochastic/slide-06.jpg></p><blockquote><p>This analogy illustrates a critical point that is central to representation learning: the right representation can make a complex task much easier to solve.</p></blockquote><p><img alt="Slide 7" loading=lazy src=/images/posts/stochastic/slide-07.jpg></p><blockquote><p>To summarize this introductory point: the difficulty of many information processing tasks is highly dependent on how that information is represented.</p></blockquote><p><img alt="Slide 8" loading=lazy src=/images/posts/stochastic/slide-08.jpg></p><blockquote><p>So, the crucial question for us is: how can we obtain a &ldquo;good representation&rdquo; for various machine learning tasks? Today, I&rsquo;ll focus on one prominent approach for achieving this: Self-Supervised Learning.</p></blockquote><p><img alt="Slide 9" loading=lazy src=/images/posts/stochastic/slide-09.jpg></p><blockquote><p>Self-Supervised Learning is a subset of the broader field of Representation Learning.</p></blockquote><p><img alt="Slide 10" loading=lazy src=/images/posts/stochastic/slide-10.jpg></p><blockquote><p>A primary motivation for the development of self-supervised methods is the immense cost and effort required to obtain large-scale labeled datasets for traditional supervised learning.</p></blockquote><p><img alt="Slide 11" loading=lazy src=/images/posts/stochastic/slide-11.jpg></p><blockquote><p>The solution that Self-Supervised Learning proposes is to find a way to learn a &ldquo;good representation&rdquo; that captures the essential features of the data using only an unlabeled dataset.</p></blockquote><p><img alt="Slide 12" loading=lazy src=/images/posts/stochastic/slide-12.jpg></p><blockquote><p>This slide illustrates the typical self-supervised learning pipeline. First, a model is trained on a &ldquo;pretext task&rdquo; using a large amount of unlabeled data. The learned model is then transferred and fine-tuned on a &ldquo;downstream task&rdquo; using task-specific (and often limited) labeled data.</p></blockquote><p><img alt="Slide 13" loading=lazy src=/images/posts/stochastic/slide-13.jpg></p><blockquote><p>The goal of the pre-training stage is to transform raw data, which can be a poor representation for a computer (like a raw image of a dog), into a feature vector that is a much better representation for downstream tasks.</p></blockquote><p><img alt="Slide 14" loading=lazy src=/images/posts/stochastic/slide-14.jpg></p><blockquote><p>The central question this paper investigates is the pre-training step: how exactly does the model learn a good representation from unlabeled data?</p></blockquote><p><img alt="Slide 15" loading=lazy src=/images/posts/stochastic/slide-15.jpg></p><blockquote><p>Within the realm of Self-Supervised Learning, I will now narrow the focus to Contrastive Learning. This approach is based on making &ldquo;inter-sample&rdquo; predictions.</p></blockquote><p><img alt="Slide 16" loading=lazy src=/images/posts/stochastic/slide-16.jpg></p><blockquote><p>Here is the core mechanic of contrastive learning. We start with an &ldquo;anchor&rdquo; image. We create two different augmented versions, or &ldquo;views,&rdquo; of this anchor, which form a &ldquo;positive pair.&rdquo; We then contrast this with a &ldquo;negative pair,&rdquo; which is formed by the anchor and a view from a completely different image.</p></blockquote><p><img alt="Slide 17" loading=lazy src=/images/posts/stochastic/slide-17.jpg></p><blockquote><p>In summary, the objective of contrastive learning is to learn effective representations by mapping similar data points close to each other in the representation space, while simultaneously pushing dissimilar data points far apart.</p></blockquote><p><img alt="Slide 18" loading=lazy src=/images/posts/stochastic/slide-18.jpg></p><blockquote><p>This slide outlines the flow of the main arguments in this review. I&rsquo;ll begin by discussing the high computational costs that arise from the conventional definition of positive and negative pairs. Then, I will introduce the paper&rsquo;s proposed method, which uses matrix approximation with I-divergence to create a decomposable and stochastic loss, ultimately achieving competitive results with a low batch size and fewer negative pairs.</p></blockquote><p><img alt="Slide 19" loading=lazy src=/images/posts/stochastic/slide-19.jpg></p><blockquote><p>Now, we move from the recap to the main introduction of the paper&rsquo;s contribution.</p></blockquote><p><img alt="Slide 20" loading=lazy src=/images/posts/stochastic/slide-20.jpg></p><blockquote><p>The core problem is that while supervised learning is effective, it depends on having extensive labeled data. Self-Supervised Learning is the alternative we are exploring.</p></blockquote><p><img alt="Slide 21" loading=lazy src=/images/posts/stochastic/slide-21.jpg></p><blockquote><p>However, popular contrastive learning methods like SimCLR require very large batch sizes to ensure a sufficient balance of positive and negative examples. This expends a large amount of computational resources, particularly on the negative pairs. A method called Sog-CLR attempted to address this by mixing an EMA of image similarities into the denominator of the InfoNCE loss.</p></blockquote><p><img alt="Slide 22" loading=lazy src=/images/posts/stochastic/slide-22.jpg></p><blockquote><p>To be more specific, SimCLR&rsquo;s InfoNCE loss operates in a full-batch mode, which is not decomposable in a mini-batch setting. Sog-CLR showed improvement by incorporating a running average for the negative pair estimations.</p></blockquote><p><img alt="Slide 23" loading=lazy src=/images/posts/stochastic/slide-23.jpg></p><blockquote><p>This paper poses the question: even with Sog-CLR&rsquo;s improvements, is there still room for further optimization? It introduces SACLR, a method that uses I-divergence to reformulate the objective into a matrix approximation problem that is decomposable across instance pairs.</p></blockquote><p><img alt="Slide 24" loading=lazy src=/images/posts/stochastic/slide-24.jpg></p><blockquote><p>The key idea behind SACLR is this reformulation using I-divergence, which allows the objective to be decomposed and approximated stochastically. This is presented as an advancement over Sog-CLR&rsquo;s EMA mixing approach.</p></blockquote><p><img alt="Slide 25" loading=lazy src=/images/posts/stochastic/slide-25.jpg></p><blockquote><p>The paper&rsquo;s central claim is that its method, SACLR, can learn high-quality representations with a small batch size and very few negative pairs. While reviewers found the core idea of tackling the large batch size problem to be an interesting and valuable contribution, and saw the novel formulation inspired by Stochastic Cluster Embedding as a strength, they heavily scrutinized the experimental evidence supporting these claims.</p></blockquote><p><img alt="Slide 26" loading=lazy src=/images/posts/stochastic/slide-26.jpg></p><blockquote><p>To understand SACLR, we first need to look at its theoretical foundation: Stochastic Cluster Embedding (SCE). I will now detail the matrix approximation with I-divergence that underpins the method.</p></blockquote><p><img alt="Slide 27" loading=lazy src=/images/posts/stochastic/slide-27.jpg></p><blockquote><p>In SCE, we have embedded data points, like $y_i$ and $y_j$. We define a similarity kernel $q_{ij}$ between these points in the embedded space, typically using a Gaussian or a Student&rsquo;s t-distribution kernel. This value should be close to 1 for similar points.</p></blockquote><p><img alt="Slide 28" loading=lazy src=/images/posts/stochastic/slide-28.jpg></p><blockquote><p>We also define a target similarity matrix, P, which represents the desired similarities in the embedded space. For example, perfectly clustered data would have a block-diagonal P matrix.</p></blockquote><p><img alt="Slide 29" loading=lazy src=/images/posts/stochastic/slide-29.jpg></p><blockquote><p>The goal is to make the learned similarity matrix Q as close as possible to our desirable target matrix P. The question is, how do we measure this closeness?</p></blockquote><p><img alt="Slide 30" loading=lazy src=/images/posts/stochastic/slide-30.jpg></p><blockquote><p>This is where the choice of divergence metric is crucial. t-SNE uses the KL-divergence. In contrast, SCE uses the I-divergence, which includes an additional scaling factor &rsquo;s&rsquo; and linear terms.</p></blockquote><p><img alt="Slide 31" loading=lazy src=/images/posts/stochastic/slide-31.jpg></p><blockquote><p>This slide highlights the formulas for both KL-divergence, used in t-SNE, and the I-divergence with a scaling factor, used in SCE.</p></blockquote><p><img alt="Slide 32" loading=lazy src=/images/posts/stochastic/slide-32.jpg></p><blockquote><p>An important property is that the I-divergence can reduce to the KL-divergence. This happens if the scaling factor &rsquo;s&rsquo; is set to be the inverse of the sum of all kernel similarities, effectively normalizing the Q matrix.</p></blockquote><p><img alt="Slide 33" loading=lazy src=/images/posts/stochastic/slide-33.jpg></p><blockquote><p>SCE defines the scaling factor &rsquo;s&rsquo; using a weighted sum controlled by the parameter α, which introduces additional repulsion to improve cluster quality. A key methodological point, raised by Reviewer C43T, was why &rsquo;s&rsquo; is treated as a constant during optimization when it is a function of the embeddings. The authors clarified that they use an interleaving optimization strategy: the model parameters are optimized while &rsquo;s&rsquo; is fixed, and then &rsquo;s&rsquo; is periodically updated based on the new embeddings.</p></blockquote><p><img alt="Slide 34" loading=lazy src=/images/posts/stochastic/slide-34.jpg></p><blockquote><p>By plugging this definition of the weights $w_{ij}$ into the formula for &rsquo;s&rsquo;, the denominator term can be rewritten as a sum of two expectations.</p></blockquote><p><img alt="Slide 35" loading=lazy src=/images/posts/stochastic/slide-35.jpg></p><blockquote><p>These two expectations have clear interpretations: $E_1$ is the expected similarity for pairs drawn from the target distribution P, while $E_2$ is the expected similarity for pairs drawn uniformly at random from all possible pairs.</p></blockquote><p><img alt="Slide 36" loading=lazy src=/images/posts/stochastic/slide-36.jpg></p><blockquote><p>This formulation allows the I-divergence objective to be rewritten in a stochastic form, separating it into an attraction term based on the target distribution and a repulsion term based on the uniform distribution. The terms themselves are simple functions of the similarity $q_{ij}$.</p></blockquote><p><img alt="Slide 37" loading=lazy src=/images/posts/stochastic/slide-37.jpg></p><blockquote><p>Now, let&rsquo;s apply this SCE framework to Contrastive Learning. In our setting, for each input $x_i$, we generate two augmented views, $\tilde{x}<em>{i}^{(1)}$ and $\tilde{x}</em>{i}^{(2)}$. We denote their embeddings as $\tilde{y}<em>{i}^{(u)}$ and the similarity between any two embeddings as $q</em>{ij}^{(u,v)}$.</p></blockquote><p><img alt="Slide 38" loading=lazy src=/images/posts/stochastic/slide-38.jpg></p><blockquote><p>The goal in contrastive learning is to make embeddings from the same instance ($i=j$) similar, and embeddings from different instances ($i \ne j$) dissimilar. We can formally define this as a target tensor $p$, where the target similarity is 1 only for positive pairs ($p_{ii}^{(1,2)}$ and $p_{ii}^{(2,1)}$) and 0 for all other pairs.</p></blockquote><p><img alt="Slide 39" loading=lazy src=/images/posts/stochastic/slide-39.jpg></p><blockquote><p>This slide provides a concrete example of the target tensor $P$ for a case with N=3 instances. The matrices for same-view similarities ($P^{(1,1)}, P^{(2,2)}$) are all zeros, while the matrices for cross-view similarities ($P^{(1,2)}, P^{(2,1)}$) are identity matrices, capturing the positive pair targets.</p></blockquote><p><img alt="Slide 40" loading=lazy src=/images/posts/stochastic/slide-40.jpg></p><blockquote><p>To simplify the math, we can flatten this four-dimensional tensor structure into standard 2D matrices. The $2N \times 2N$ target matrix $\psi$ is formed by reorganizing the elements of the tensor $p$. This results in a sparse matrix where the identity matrices from the tensor become off-diagonal blocks.</p></blockquote><p><img alt="Slide 41" loading=lazy src=/images/posts/stochastic/slide-41.jpg></p><blockquote><p>For notational simplicity, we neglect the diagonal elements of the matrices $\psi$ and $\phi$ in the approximation, as they are constant for the kernels used and do not affect the optimization.</p></blockquote><p><img alt="Slide 42" loading=lazy src=/images/posts/stochastic/slide-42.jpg></p><blockquote><p>Now we apply the SCE I-divergence formula, but to our new flattened matrices $\psi$ and $\phi$ which represent the contrastive learning problem.</p></blockquote><p><img alt="Slide 43" loading=lazy src=/images/posts/stochastic/slide-43.jpg></p><blockquote><p>Applying the I-divergence $D_{I}(\psi||s\phi)$ and using the specific structure of our target matrix $\psi$ (which is mostly zeros), the loss function simplifies significantly. The scaling factor $s$ is updated periodically, with its weights $w_{ij}^{u,v}$ also adapted for the contrastive case.</p></blockquote><p><img alt="Slide 44" loading=lazy src=/images/posts/stochastic/slide-44.jpg></p><blockquote><p>The full loss function $\mathcal{L}<em>{CLR}(\theta)$ can be expressed as an expectation over the data indices. This form consists of a term for positive pairs ($log~q</em>{ii}^{1,2}$) and a repulsion term involving a sum of similarities over all pairs.</p></blockquote><p><img alt="Slide 45" loading=lazy src=/images/posts/stochastic/slide-45.jpg></p><blockquote><p>To make this computationally feasible, we use a Monte Carlo approximation. This gives us the final SACLR objective, $\mathcal{L}<em>{SACLR}(\theta)$, which is calculated over a mini-batch $\mathcal{B}$ and a set of M negative samples $\mathcal{M}</em>{i}$. The paper studies two variants: SACLR-1 (M=1) and SACLR-all (M=B).</p></blockquote><p><img alt="Slide 46" loading=lazy src=/images/posts/stochastic/slide-46.jpg></p><blockquote><p>The scaling factor $s$ is also estimated stochastically. Its inverse, $s^{-1}$, is approximated using samples from the mini-batch, and this estimate is updated smoothly using an exponential moving average (EMA) after each batch.</p></blockquote><p><img alt="Slide 47" loading=lazy src=/images/posts/stochastic/slide-47.jpg></p><blockquote><p>The paper also explores a row-wise decomposition of the matrix approximation. Instead of one global scaling factor &rsquo;s&rsquo;, each row &lsquo;a&rsquo; of the similarity matrix gets its own scaling factor $s_a$. This results in the loss function $\mathcal{L}_{CLR-row}(\theta)$.</p></blockquote><p><img alt="Slide 48" loading=lazy src=/images/posts/stochastic/slide-48.jpg></p><blockquote><p>This slide provides proof for the simplified row-wise SACLR loss function. By substituting the sparse target matrix $\psi$ into the general I-divergence formula and summing over all rows, we arrive at the expression shown.</p></blockquote><p><img alt="Slide 49" loading=lazy src=/images/posts/stochastic/slide-49.jpg></p><blockquote><p>A key theoretical finding presented in the paper is that under specific conditions, the SACLR-row objective becomes equivalent to the SimCLR loss. This link, however, became a point of discussion during the review. Reviewer gz9D argued that this equivalence doesn&rsquo;t explain why SACLR should be expected to <em>outperform</em> SimCLR. The authors countered that the method&rsquo;s advantage comes not from this specific condition, but from using a different, more flexible weighting scheme for the scaling factor.</p></blockquote><p><img alt="Slide 50" loading=lazy src=/images/posts/stochastic/slide-50.jpg></p><blockquote><p>Here is the proof of Theorem 3.1. By substituting the condition for the scaling factors into the loss function, the repulsion term simplifies to a constant, and the remaining terms can be rearranged to form precisely the SimCLR objective.</p></blockquote><p><img alt="Slide 51" loading=lazy src=/images/posts/stochastic/slide-51.jpg></p><blockquote><p>Just as with the full matrix version, the row-wise loss can be approximated stochastically for mini-batch training. This gives us the $\mathcal{L}_{SACLR-row}(\theta)$ objective.</p></blockquote><p><img alt="Slide 52" loading=lazy src=/images/posts/stochastic/slide-52.jpg></p><blockquote><p>Similarly, the row-wise scaling factors $s_{2(i-1)+u}$ are estimated stochastically within each mini-batch and updated using an EMA rule.</p></blockquote><p><img alt="Slide 53" loading=lazy src=/images/posts/stochastic/slide-53.jpg></p><blockquote><p>This diagram provides a summary of the theoretical framework I have just presented. We started with the concept of I-divergence and a scaling factor, which we used to build a matrix approximation. This was then decomposed row-wise, and both versions were made practical via stochastic approximation. Now, it&rsquo;s time to see the experimental results.</p></blockquote><p><img alt="Slide 54" loading=lazy src=/images/posts/stochastic/slide-54.jpg></p><blockquote><p>This slide presents the full pseudocode for the SACLR algorithm. A major point of contention in the initial review was that the paper claimed to be &ldquo;more computationally efficient&rdquo; without providing empirical data on runtime or memory. The detailed ablation studies on computational cost, shown later in the presentation, were added during the rebuttal period as a direct response to this criticism from the reviewers.</p></blockquote><p><img alt="Slide 55" loading=lazy src=/images/posts/stochastic/slide-55.jpg></p><blockquote><p>Now we move to the experiments section. The standard evaluation protocol for self-supervised methods is used: first, a model is pre-trained without labels on a dataset like ImageNet or CIFAR. The learned weights from this backbone are then used to initialize a new network, a linear layer is added, and this new network is trained with labels to perform a classification task.</p></blockquote><p><img alt="Slide 56" loading=lazy src=/images/posts/stochastic/slide-56.jpg></p><blockquote><p>Table 1 shows the Top-1 linear classification accuracies on ImageNet. While SACLR-ALL is shown to be competitive with some methods like MoCo v2, this comparison drew significant criticism during the review process. The Area Chair and multiple reviewers stated that the baseline methods used for comparison were &ldquo;weak&rdquo; and the performance gains &ldquo;marginal,&rdquo; noting that many stronger, more recent methods were omitted.</p></blockquote><p><img alt="Slide 57" loading=lazy src=/images/posts/stochastic/slide-57.jpg></p><blockquote><p>This table shows results for longer training, with SACLR-MIX surpassing SimCLR and SogCLR in this setup. However, reviewers found this comparison inadequate as well. Reviewer gz9D pointed out that results for top-performing methods like VICReg and Barlow Twins from other benchmark papers were significantly higher. The authors argued their goal was primarily efficiency without heavy tuning, but this did not overcome the concerns about the weak comparison set.</p></blockquote><p><img alt="Slide 58" loading=lazy src=/images/posts/stochastic/slide-58.jpg></p><blockquote><p>This experiment in Table 3 specifically investigates performance when using only a single negative sample (M=1) per image. SACLR-1 achieves a Top-1 accuracy of 65.3%, significantly outperforming classical contrastive losses like Triplet and Logistic loss under the same constraint.</p></blockquote><p><img alt="Slide 59" loading=lazy src=/images/posts/stochastic/slide-59.jpg></p><blockquote><p>This table evaluates semi-supervised learning performance, showing SACLR&rsquo;s strength in data-limited regimes. It is worth noting that the initial submission focused almost exclusively on linear evaluation. Reviewers Tx4K and gz9D strongly recommended including more comprehensive evaluations like semi-supervised fine-tuning to provide a more complete picture, and the additional kNN and fine-tuning results were added to the paper in response.</p></blockquote><p><img alt="Slide 60" loading=lazy src=/images/posts/stochastic/slide-60.jpg></p><blockquote><p>The learned representations are also evaluated on transfer learning classification tasks. As shown in Table 5, the representations learned by SACLR-ALL and SACLR-MIX transfer very well to other datasets like VOC07 and especially iNaturalist18, where they significantly outperform SimCLR and MoCo v2.</p></blockquote><p><img alt="Slide 61" loading=lazy src=/images/posts/stochastic/slide-61.jpg></p><blockquote><p>Table 6 shows transfer learning results on more complex downstream tasks: object detection and segmentation on VOC and COCO. Across all metrics, the SACLR variants are highly competitive and often outperform strong baselines like SimCLR, BYOL, and MoCo v2, with SACLR-MIX showing the strongest results overall.</p></blockquote><p><img alt="Slide 62" loading=lazy src=/images/posts/stochastic/slide-62.jpg></p><blockquote><p>This table provides a direct comparison with other stochastic estimation-based contrastive methods, using an architecture similar to the iSog-CLR paper for a fair comparison. The results on CIFAR10, CIFAR100, and ImageNet100 show that both the matrix and row versions of SACLR are highly competitive, often achieving the best or second-best performance in this specific class of methods.</p></blockquote><p><img alt="Slide 63" loading=lazy src=/images/posts/stochastic/slide-63.jpg></p><blockquote><p>This slide presents several ablation studies on computational complexity and robustness. These experiments were largely added in response to direct reviewer feedback. Reviewers requested empirical data on runtime and memory to substantiate the paper&rsquo;s efficiency claims, as well as a study on the impact of batch size to support the claim that SACLR performs well in small-batch settings. These tables represent the authors&rsquo; attempt to provide that missing evidence.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://mookjsi.github.io/tags/paper-review/>Paper Review</a></li><li><a href=https://mookjsi.github.io/tags/self-supervised-learning/>Self-Supervised Learning</a></li><li><a href=https://mookjsi.github.io/tags/contrastive-learning/>Contrastive Learning</a></li><li><a href=https://mookjsi.github.io/tags/stochastic-approximation/>Stochastic Approximation</a></li><li><a href=https://mookjsi.github.io/tags/iclr-2025/>ICLR 2025</a></li></ul><nav class=paginav><a class=prev href=https://mookjsi.github.io/posts/paper-review-maxtoken/><span class=title>« Prev</span><br><span>Max-Margin Token Selection in Attention Mechanism</span>
</a><a class=next href=https://mookjsi.github.io/posts/paper-review-whentoretrieve/><span class=title>Next »</span><br><span>When to Retrieve?</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on x" href="https://x.com/intent/tweet/?text=Stochastic%20Approximation%20to%20Contrastive%20Learning&amp;url=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f&amp;hashtags=PaperReview%2cSelf-SupervisedLearning%2cContrastiveLearning%2cStochasticApproximation%2cICLR2025"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f&amp;title=Stochastic%20Approximation%20to%20Contrastive%20Learning&amp;summary=Stochastic%20Approximation%20to%20Contrastive%20Learning&amp;source=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f&title=Stochastic%20Approximation%20to%20Contrastive%20Learning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on whatsapp" href="https://api.whatsapp.com/send?text=Stochastic%20Approximation%20to%20Contrastive%20Learning%20-%20https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on telegram" href="https://telegram.me/share/url?text=Stochastic%20Approximation%20to%20Contrastive%20Learning&amp;url=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stochastic Approximation to Contrastive Learning on ycombinator" href="https://news.ycombinator.com/submitlink?t=Stochastic%20Approximation%20to%20Contrastive%20Learning&u=https%3a%2f%2fmookjsi.github.io%2fposts%2fpaper-review-stochastic%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>© 2025 Jungmook Kang</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>