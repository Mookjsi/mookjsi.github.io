[{"content":"[cite_start]I\u0026rsquo;m sharing my full slide-by-slide review of the paper Promptriever: Instruction-Trained Retrievers, which was presented at ICLR 2025. [cite: 65]\nThe paper tackles a big problem in current search models: they often fail to understand complex requests, especially negative ones (like \u0026ldquo;not A, but B\u0026rdquo;). The authors\u0026rsquo; solution is Promptriever, a new model trained with a special dataset that forces it to actually follow instructions.\nLet\u0026rsquo;s go through my 35 slides to see how they did it.\nSlide 1: Title Slide [cite_start]This is my presentation on \u0026ldquo;Promptriever: Instruction-Trained Retrievers,\u0026rdquo; which I put together for the Information Theory and Machine Learning Lab. [cite: 58, 59, 61, 62, 63, 64]\nSlide 2: Authors and Affiliations (1) First, let\u0026rsquo;s acknowledge the researchers. [cite_start]The lead author is Orion Weller, who is affiliated with Johns Hopkins and Samaya AI. [cite: 67, 68, 69, 70] [cite_start]It\u0026rsquo;s also worth noting this work was accepted as a poster at ICLR 2025. [cite: 65, 66]\nSlide 3: The Core Message I want to start with the paper\u0026rsquo;s core claim, which I think is really powerful. [cite_start]The authors state that their new training method is the first to prove that search models can be \u0026ldquo;intelligent, instruction-following partners, not just data finders.\u0026rdquo; [cite: 71, 72]\nSlide 4: Authors and Affiliations (2) [cite_start]Here are the other co-authors who contributed to this research. [cite: 75, 76, 78, 79, 81]\nSlide 5: Table of Contents (Motivation) I\u0026rsquo;ve structured this review into three parts: Motivation, the Promptriever model, and the Experiments. [cite_start]We\u0026rsquo;ll start with the motivation behind the research. [cite: 73, 74, 77, 80]\nSlide 6: The Problem with Modern Search So, how do current search engines \u0026ldquo;think\u0026rdquo;? [cite_start]They mostly use a retriever based on semantic similarity to rank documents. [cite: 84, 86, 87, 89] [cite_start]On the surface, this seems fine, but what\u0026rsquo;s the problem? [cite: 88]\nSlide 7: A Concrete Example of the Problem This example makes the problem obvious. [cite_start]Imagine you need a laptop that is not a MacBook and costs under $1000. [cite: 92] [cite_start]A standard retriever sees the keywords \u0026ldquo;MacBook\u0026rdquo; and \u0026ldquo;under $1000\u0026rdquo; in an article about the MacBook Air and incorrectly flags it as highly relevant. [cite: 93, 94, 95, 96, 97, 98, 99, 100, 101]\nSlide 8: The Flawed User Experience This leads to a frustrating user experience. [cite_start]You\u0026rsquo;re forced to keep tweaking keywords and filters just to find what you want. [cite: 109, 110, 111, 112]\nSlide 9: The Solution: How Promptriever Thinks This is where Promptriever comes in. It doesn\u0026rsquo;t just use semantic similarity. [cite_start]Instead, it operates on \u0026ldquo;dynamic relevance definitions,\u0026rdquo; which allows for a much more intelligent process. [cite: 113, 114, 117, 118]\nSlide 10: Promptriever in Action Let\u0026rsquo;s look at the same query again, but with Promptriever. [cite_start]It correctly understands the instructions—the core topic, the exclusion of MacBooks, and the price constraint. [cite: 122, 123, 124] [cite_start]Because of this, it successfully returns a relevant document about a Dell XPS 13. [cite: 125, 126, 127]\nSlide 11: The Power of Dynamic Relevance [cite_start]The key idea here is that Promptriever \u0026ldquo;dynamically adjusts relevance based on your natural language instructions.\u0026rdquo; [cite: 133] It\u0026rsquo;s not just matching words; it\u0026rsquo;s understanding commands.\nSlide 12: The Crucial Question [cite_start]We\u0026rsquo;ve seen what it does, which leads to the next question: \u0026ldquo;But how on earth was this made?\u0026rdquo; [cite: 137] Let\u0026rsquo;s get into the technical details.\nSlide 13: Table of Contents (Promptriever) [cite_start]Now, we\u0026rsquo;ll dive into the second section, where I\u0026rsquo;ll break down the Promptriever model\u0026rsquo;s architecture and training. [cite: 138]\nSlide 14: The Components of Promptriever [cite_start]The architecture is a combination of the LLaMA-2 7B language model and a Bi-encoder. [cite: 139, 140, 141, 142, 143]\nSlide 15: The Core Technical Challenge [cite_start]The main technical hurdle they faced is a well-known one: standard fine-tuning for information retrieval often destroys a model\u0026rsquo;s instruction-following ability. [cite: 149, 150] So how did they keep the model intelligent?\nSlide 16: The Key to the Solution [cite_start]The answer, as they stated in their core message, lies in their \u0026ldquo;novel training data, which makes ignoring commands impossible for correct answers.\u0026rdquo; [cite: 157]\nSlide 17: Traditional Training Data [cite_start]For context, standard retrieval models are trained on simple (Query, Document) pairs from datasets like MSMARCO. [cite: 158, 159, 160, 161]\nSlide 18: Promptriever\u0026rsquo;s Advanced Training Data [cite_start]Promptriever, however, uses a much richer format: Query + Instruction paired with Synthetic documents. [cite: 165, 182] [cite_start]This is what lets them train the model on complex, instruction-based prompts. [cite: 176, 180]\nSlide 19: The \u0026ldquo;Instruction-Negative\u0026rdquo; Concept The most clever part of their training data is the Instruction-Negative. [cite_start]This is a document that\u0026rsquo;s correct for the query alone, but becomes incorrect when the instruction is added. [cite: 189, 190] This is what forces the model to pay attention.\nSlide 20: Example of an Instruction-Negative Here’s a perfect example. [cite_start]For the query \u0026ldquo;What is the capital of France?,\u0026rdquo; a general article about Paris is a good result. [cite: 216] [cite_start]But if you add the instruction \u0026ldquo;mention its average annual rainfall,\u0026rdquo; that article is now an instruction-negative, and a new document with rainfall data becomes the right answer. [cite: 212, 217]\nSlide 21: How the Training Works [cite_start]Through this process, the model learns that if it ignores the instruction, it will retrieve the wrong results. [cite: 226] [cite_start]To get the right answer, it has to carefully read and follow the command. [cite: 227, 228]\nSlide 22: Ensuring Dataset Quality (1) The authors were careful about quality control. They found that about 15% of their generated instructions made the original document irrelevant. [cite_start]For those cases, they used an LLM to generate a new, correct document as a substitute. [cite: 237, 238, 239, 240]\nSlide 23: Ensuring Dataset Quality (2) Creating these instruction-negatives was absolutely essential. Without them, the model could have just learned to ignore the instructions and still perform well on the base dataset. [cite_start]The negatives guarantee true instruction-following. [cite: 249, 250, 251]\nSlide 24: Table of Contents (Experiments) [cite_start]Now for the final section, \u0026ldquo;Experiments,\u0026rdquo; where we\u0026rsquo;ll look at the results. [cite: 252]\nSlide 25: Experiment Settings (1) [cite_start]For a fair comparison, they ran an \u0026ldquo;Apples-to-Apples\u0026rdquo; test against RepLLaMA, using the exact same data and hyperparameters. [cite: 254, 255, 256, 257, 258]\nSlide 26: Experiment Settings (2) [cite_start]They used a range of datasets and evaluated performance with metrics like NDCG@10, MRR, and importantly, p-MRR, which is designed to measure sensitivity to instructions. [cite: 260, 265, 266, 267, 270, 272]\nSlide 27: Summary of Results ![Slide 27](/images/posts/promptriever/slide-27.jpg\u0026gt;\n[cite_start]The results were impressive. In short, Promptriever achieved state-of-the-art performance, showed better robustness, and could be improved zero-shot just by prompting. [cite: 274, 275, 276, 277, 278]\nSlide 28: Detailed Results (Table 1) This table gives a detailed breakdown. [cite_start]You can see that Promptriever gets high scores across the board, but it really shines in the p-MRR metric, which confirms its superior instruction-following ability. [cite: 279, 280]\nSlide 29: In-Domain Performance On the in-domain MSMARCO dataset, the performance was on par with the strong RepLLaMA baseline. This is great because it shows that the model gained its new skills without sacrificing core retrieval performance.\nSlide 30: Out-of-Domain Performance (BEIR) This is where it gets interesting. When given a helpful prompt, Promptriever\u0026rsquo;s performance on out-of-domain datasets actually improves, while other models get worse. This proves that it is genuinely \u0026ldquo;promptable.\u0026rdquo;\nSlide 31: Robustness Results This table looks at the standard deviation of scores across different prompts. Promptriever\u0026rsquo;s lower deviation means its performance is much more stable and consistent, regardless of how the query is phrased.\nSlide 32: Ablation Study The ablation study confirms it all. The performance gains are a direct result of the instruction-based training with instruction-negatives, not because of other factors like longer queries.\nSlide 33: Generalization to Other Models The authors also proved their training \u0026ldquo;recipe\u0026rdquo; is general. It works well on other base models like Mistral and Llama 3, not just LLaMA-2. As they put it, \u0026ldquo;A golden recipe doesn\u0026rsquo;t discriminate against ingredients!\u0026rdquo;\nSlide 34: Rebuttal (1) Finally, let\u0026rsquo;s look at the reviewer feedback. When one reviewer claimed the data comparison was unfair, the authors argued that the data generation method is their core contribution. They also clarified that comparing to techniques like query rewriting was out of the paper\u0026rsquo;s scope.\nSlide 35: Rebuttal (2) In the end, the authors addressed all concerns. They ran the requested statistical tests and added more real-world examples during the rebuttal period, which satisfied the reviewers and got the paper accepted.\n","permalink":"https://mookjsi.github.io/posts/paper-review-promptriever/","summary":"Here\u0026rsquo;s my full 35-slide review of the ICLR 2025 paper, Promptriever. In this post, I break down the core concepts, training methods, and results of a new retriever that\u0026rsquo;s trained to follow natural language instructions.","title":"My Paper Review: Promptriever - Instruction-Trained Retrievers"},{"content":"Education Yonsei University, Seoul, Korea Senior @ Dept. of Applied Statistics GPA: 4.16/4.3 (Overall), 4.24/4.3 (Statistics) Research Interests Statistical Machine Learning Large Language Model Retrieval Method Research Experience Undergraduate Researcher, ITML @ Yonsei (Jan. 2025 – Jun. 2025) Conducting undergraduate research under the supervision of Prof. Jy-yong Sohn. Engaged in ongoing projects related to RAG. Skills Programming: R, Python, Frontend, Git, MATLAB Languages: Korean (Native), English (Intermediate), Chinese (Beginner) ","permalink":"https://mookjsi.github.io/about/","summary":"\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eYonsei University\u003c/strong\u003e, Seoul, Korea\n\u003cul\u003e\n\u003cli\u003eSenior @ Dept. of Applied Statistics\u003c/li\u003e\n\u003cli\u003eGPA: 4.16/4.3 (Overall), 4.24/4.3 (Statistics)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"research-interests\"\u003eResearch Interests\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eStatistical Machine Learning\u003c/li\u003e\n\u003cli\u003eLarge Language Model\u003c/li\u003e\n\u003cli\u003eRetrieval Method\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"research-experience\"\u003eResearch Experience\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUndergraduate Researcher\u003c/strong\u003e, ITML @ Yonsei (Jan. 2025 – Jun. 2025)\n\u003cul\u003e\n\u003cli\u003eConducting undergraduate research under the supervision of Prof. Jy-yong Sohn.\u003c/li\u003e\n\u003cli\u003eEngaged in ongoing projects related to RAG.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"skills\"\u003eSkills\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProgramming:\u003c/strong\u003e R, Python, Frontend, Git, MATLAB\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLanguages:\u003c/strong\u003e Korean (Native), English (Intermediate), Chinese (Beginner)\u003c/li\u003e\n\u003c/ul\u003e","title":"About Me"}]