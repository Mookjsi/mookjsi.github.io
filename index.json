[{"content":"I\u0026rsquo;m sharing my full slide-by-slide review of the paper Promptriever: Instruction-Trained Retrievers, which was presented at ICLR 2025.\nThe paper tackles a big problem in current search models: they often fail to understand complex requests, especially negative ones (like \u0026ldquo;not A, but B\u0026rdquo;). The authors\u0026rsquo; solution is Promptriever, a new model trained with a special dataset that forces it to actually follow instructions.\nThis is my presentation on \u0026ldquo;Promptriever: Instruction-Trained Retrievers,\u0026rdquo; which I put together for the Information Theory and Machine Learning Lab.\nFirst, let\u0026rsquo;s acknowledge the researchers. The lead author is Orion Weller, who is affiliated with Johns Hopkins and Samaya AI. It\u0026rsquo;s also worth noting this work was accepted as a poster at ICLR 2025.\nI want to start with the paper\u0026rsquo;s core claim, which I think is really powerful. The authors state that their new training method is the first to prove that search models can be \u0026ldquo;intelligent, instruction-following partners, not just data finders.\u0026rdquo;\nHere are the other co-authors who contributed to this research.\nI\u0026rsquo;ve structured this review into three parts: Motivation, the Promptriever model, and the Experiments. We\u0026rsquo;ll start with the motivation behind the research.\nSo, how do current search engines \u0026ldquo;think\u0026rdquo;? They mostly use a retriever based on semantic similarity to rank documents. On the surface, this seems fine, but what\u0026rsquo;s the problem?\nThis example makes the problem obvious. Imagine you need a laptop that is not a MacBook and costs under $1000. A standard retriever sees the keywords \u0026ldquo;MacBook\u0026rdquo; and \u0026ldquo;under $1000\u0026rdquo; in an article about the MacBook Air and incorrectly flags it as highly relevant.\nThis leads to a frustrating user experience. You\u0026rsquo;re forced to keep tweaking keywords and filters just to find what you want.\nThis is where Promptriever comes in. It doesn\u0026rsquo;t just use semantic similarity. Instead, it operates on \u0026ldquo;dynamic relevance definitions,\u0026rdquo; which allows for a much more intelligent process.\nLet\u0026rsquo;s look at the same query again, but with Promptriever. It correctly understands the instructions—the core topic, the exclusion of MacBooks, and the price constraint. Because of this, it successfully returns a relevant document about a Dell XPS 13.\nThe key idea here is that Promptriever \u0026ldquo;dynamically adjusts relevance based on your natural language instructions.\u0026rdquo; It\u0026rsquo;s not just matching words; it\u0026rsquo;s understanding commands.\nWe\u0026rsquo;ve seen what it does, which leads to the next question: \u0026ldquo;But how on earth was this made?\u0026rdquo; Let\u0026rsquo;s get into the technical details.\nNow, we\u0026rsquo;ll dive into the second section, where I\u0026rsquo;ll break down the Promptriever model\u0026rsquo;s architecture and training.\nThe architecture is a combination of the LLaMA-2 7B language model and a Bi-encoder.\nThe main technical hurdle they faced is a well-known one: standard fine-tuning for information retrieval often destroys a model\u0026rsquo;s instruction-following ability. So how did they keep the model intelligent?\nThe answer, as they stated in their core message, lies in their \u0026ldquo;novel training data, which makes ignoring commands impossible for correct answers.\u0026rdquo;\nFor context, standard retrieval models are trained on simple (Query, Document) pairs from datasets like MSMARCO.\nPromptriever, however, uses a much richer format: Query + Instruction paired with Synthetic documents. This is what lets them train the model on complex, instruction-based prompts.\nThe most clever part of their training data is the Instruction-Negative. This is a document that\u0026rsquo;s correct for the query alone, but becomes incorrect when the instruction is added. This is what forces the model to pay attention.\nHere’s a perfect example. For the query \u0026ldquo;What is the capital of France?,\u0026rdquo; a general article about Paris is a good result. But if you add the instruction \u0026ldquo;mention its average annual rainfall,\u0026rdquo; that article is now an instruction-negative, and a new document with rainfall data becomes the right answer.\nThrough this process, the model learns that if it ignores the instruction, it will retrieve the wrong results. To get the right answer, it has to carefully read and follow the command.\nThe authors were careful about quality control. They found that about 15% of their generated instructions made the original document irrelevant. For those cases, they used an LLM to generate a new, correct document as a substitute.\nCreating these instruction-negatives was absolutely essential. Without them, the model could have just learned to ignore the instructions and still perform well on the base dataset. The negatives guarantee true instruction-following.\nNow for the final section, \u0026ldquo;Experiments,\u0026rdquo; where we\u0026rsquo;ll look at the results.\nFor a fair comparison, they ran an \u0026ldquo;Apples-to-Apples\u0026rdquo; test against RepLLaMA, using the exact same data and hyperparameters.\nThey used a range of datasets and evaluated performance with metrics like NDCG@10, MRR, and importantly, p-MRR, which is designed to measure sensitivity to instructions.\nThe results were impressive. In short, Promptriever achieved state-of-the-art performance, showed better robustness, and could be improved zero-shot just by prompting.\nThis table gives a detailed breakdown. You can see that Promptriever gets high scores across the board, but it really shines in the p-MRR metric, which confirms its superior instruction-following ability.\nOn the in-domain MSMARCO dataset, the performance was on par with the strong RepLLaMA baseline. This is great because it shows that the model gained its new skills without sacrificing core retrieval performance.\nThis is where it gets interesting. When given a helpful prompt, Promptriever\u0026rsquo;s performance on out-of-domain datasets actually improves, while other models get worse. This proves that it is genuinely \u0026ldquo;promptable.\u0026rdquo;\nThis table looks at the standard deviation of scores across different prompts. Promptriever\u0026rsquo;s lower deviation means its performance is much more stable and consistent, regardless of how the query is phrased.\nThe ablation study confirms it all. The performance gains are a direct result of the instruction-based training with instruction-negatives, not because of other factors like longer queries.\nThe authors also proved their training \u0026ldquo;recipe\u0026rdquo; is general. It works well on other base models like Mistral and Llama 3, not just LLaMA-2. As they put it, \u0026ldquo;A golden recipe doesn\u0026rsquo;t discriminate against ingredients!\u0026rdquo;\nFinally, let\u0026rsquo;s look at the reviewer feedback. When one reviewer claimed the data comparison was unfair, the authors argued that the data generation method is their core contribution. They also clarified that comparing to techniques like query rewriting was out of the paper\u0026rsquo;s scope.\nIn the end, the authors addressed all concerns. They ran the requested statistical tests and added more real-world examples during the rebuttal period, which satisfied the reviewers and got the paper accepted.\n","permalink":"https://mookjsi.github.io/posts/paper-review-promptriever/","summary":"A review of the ICLR 2025 paper, Promptriever. In this post, I break down the core concepts, training methods, and results of a new retriever that\u0026rsquo;s trained to follow natural language instructions.","title":"Promptriever - Instruction-Trained Retrievers"},{"content":"Education Yonsei University, Seoul, Korea Senior @ Dept. of Applied Statistics GPA: 4.16/4.3 (Overall), 4.24/4.3 (Statistics) Research Interests Statistical Machine Learning Large Language Model Retrieval Method Research Experience Undergraduate Researcher, ITML @ Yonsei (Jan. 2025 – Jun. 2025) Conducting undergraduate research under the supervision of Prof. Jy-yong Sohn. Engaged in ongoing projects related to RAG. Skills Programming: R, Python, Frontend, Git, MATLAB Languages: Korean (Native), English (Intermediate), Chinese (Beginner) ","permalink":"https://mookjsi.github.io/about/","summary":"\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eYonsei University\u003c/strong\u003e, Seoul, Korea\n\u003cul\u003e\n\u003cli\u003eSenior @ Dept. of Applied Statistics\u003c/li\u003e\n\u003cli\u003eGPA: 4.16/4.3 (Overall), 4.24/4.3 (Statistics)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"research-interests\"\u003eResearch Interests\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eStatistical Machine Learning\u003c/li\u003e\n\u003cli\u003eLarge Language Model\u003c/li\u003e\n\u003cli\u003eRetrieval Method\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"research-experience\"\u003eResearch Experience\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUndergraduate Researcher\u003c/strong\u003e, ITML @ Yonsei (Jan. 2025 – Jun. 2025)\n\u003cul\u003e\n\u003cli\u003eConducting undergraduate research under the supervision of Prof. Jy-yong Sohn.\u003c/li\u003e\n\u003cli\u003eEngaged in ongoing projects related to RAG.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"skills\"\u003eSkills\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProgramming:\u003c/strong\u003e R, Python, Frontend, Git, MATLAB\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLanguages:\u003c/strong\u003e Korean (Native), English (Intermediate), Chinese (Beginner)\u003c/li\u003e\n\u003c/ul\u003e","title":"About Me"}]