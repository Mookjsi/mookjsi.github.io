<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>NeurIPS 2025 on MookStudy</title>
    <link>https://mookjsi.github.io/tags/neurips-2025/</link>
    <description>Recent content in NeurIPS 2025 on MookStudy</description>
    <generator>Hugo -- 0.153.2</generator>
    <language>en</language>
    <copyright>2025 Jungmook Kang</copyright>
    <lastBuildDate>Wed, 30 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mookjsi.github.io/tags/neurips-2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Max-Margin Token Selection in Attention Mechanism</title>
      <link>https://mookjsi.github.io/posts/paper-review-maxtoken/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mookjsi.github.io/posts/paper-review-maxtoken/</guid>
      <description>This post reviews the NeurIPS 2025 paper &amp;lsquo;Max-Margin Token Selection in Attention Mechanism.&amp;rsquo; The paper analyzes the theoretical foundations and implicit bias of the attention mechanism, explaining why attention focuses on important tokens and how this process is connected to margin maximization in SVMs.</description>
    </item>
  </channel>
</rss>
